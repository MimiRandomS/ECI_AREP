# ğŸ“˜ Retrieval-Augmented Generation (RAG) with OpenAI & Pinecone

**Autor:** Geronimo
**Repositorio:** [github.com/MimiRandomS](https://github.com/MimiRandomS)

---

## ğŸ§  DescripciÃ³n del Proyecto

Este proyecto implementa un **sistema RAG (Retrieval-Augmented Generation)** utilizando **LangChain**, **OpenAI** y **Pinecone**.
El objetivo es crear una aplicaciÃ³n capaz de **responder preguntas con informaciÃ³n contextual extraÃ­da de documentos locales**.
El sistema combina un **modelo generativo (LLM)** con un **motor de recuperaciÃ³n semÃ¡ntica (vector database)** para producir respuestas mÃ¡s precisas y fundamentadas.

---

## ğŸ§© Arquitectura General

```
ğŸ“ rag_openai_pinecone/
â”‚
â”œâ”€â”€ .env_example                  # Variables de entorno de ejemplo
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â”œâ”€â”€ data/                         # Carpeta donde van los documentos (.txt)
â”‚   â””â”€â”€ Inteligencia_artificial.txt
â””â”€â”€ src/
    â”œâ”€â”€ ingest_data.py            # Script que ingesta documentos en Pinecone
    â”œâ”€â”€ query_rag.py              # Script principal para consultar el RAG
    â””â”€â”€ verificar_indices.py      # Script auxiliar para verificar Ã­ndices
```

---

## âš™ï¸ TecnologÃ­as Utilizadas

* **Python 3.11+**
* **LangChain** â†’ Framework de orquestaciÃ³n para LLMs
* **OpenAI API** â†’ Modelos GPT-4o-mini y text-embedding-3-small
* **Pinecone** â†’ Base de datos vectorial (serverless)
* **dotenv** â†’ Manejo de variables de entorno
* **tiktoken** â†’ Tokenizador para embeddings
* **Sentence-Transformers / HuggingFace** â†’ Alternativa para embeddings locales

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/MimiRandomS/rag_openai_pinecone.git
cd rag_openai_pinecone
```

### 2ï¸âƒ£ Crear y activar entorno virtual

```bash
python -m venv .venv
.\.venv\Scripts\activate
```

### 3ï¸âƒ£ Instalar dependencias

```bash
pip install -r requirements.txt
```

Contenido del `requirements.txt`:

```
langchain
langchain-community
openai
python-dotenv
tiktoken
langchain_openai
pinecone
langchain-text-splitters
langchain-huggingface
sentence-transformers
```

---

## ğŸ”‘ Variables de Entorno

Crea un archivo `.env` en la raÃ­z del proyecto (basado en `.env_example`):

```env
OPENAI_API_KEY=sk-...tu_clave_openai...
PINECONE_API_KEY=pcsk_...tu_clave_pinecone...
PINECONE_ENVIRONMENT=us-east-1
```
---

## ğŸ§© Paso a Paso: EjecuciÃ³n

### 1ï¸âƒ£ Ingestar los documentos

Guarda tus archivos `.txt` dentro de la carpeta `/data`. Agrega todos los documentos que requiera el RAG para dar respues entrenadas y acertadas.
Ejemplo:

```
data/
 â””â”€â”€ Inteligencia_artificial.txt
```

Luego ejecuta:

```bash
python src/ingest_data.py
```

Esto:

* Divide los textos en fragmentos.
* Crea un Ã­ndice en Pinecone (`rag-demo-local-index`).
* Inserta los embeddings generados.

âœ… VerÃ¡s mensajes como:

```
âœ… Pinecone inicializado
ğŸ“– Inteligencia_artificial.txt
ğŸ“„ 1 documentos cargados
ğŸ”ª 5 fragmentos creados
âœ… Documentos indexados
ğŸ“Š Vectores en Ã­ndice: 5
```

---

### 2ï¸âƒ£ Consultar el sistema RAG

Ejecuta:

```bash
python src/query_rag.py
```

Ejemplo de interacciÃ³n:

```
âœ… Ãndice conectado: rag-demo-index
ğŸš€ Sistema RAG inicializado correctamente.

ğŸ’¬ Pregunta (o 'exit'): inteligencia artificial

ğŸ¤– La inteligencia artificial (IA) es un campo de la informÃ¡tica que busca crear sistemas capaces de realizar tareas que normalmente requieren inteligencia humana...
```

---

### 3ï¸âƒ£ Verificar Ã­ndices creados

```bash
python src/verificar_indices.py
```

Salida esperada:

```
ğŸ“Š Ãndices disponibles:
  - rag-demo-index: 5 vectores, dim: 1536
  - rag-demo-local-index: 10 vectores, dim: 384
```

---

## ğŸ§  Concepto de RAG

**RAG (Retrieval-Augmented Generation)** combina dos componentes:

| Componente          | FunciÃ³n                                               | TecnologÃ­a            |
| ------------------- | ----------------------------------------------------- | --------------------- |
| **Retriever**       | Busca informaciÃ³n relevante en una base vectorial     | Pinecone + Embeddings |
| **Generator (LLM)** | Genera una respuesta basada en el contexto recuperado | OpenAI GPT-4o-mini    |

ğŸ“Š Flujo:

1. El usuario formula una pregunta.
2. Se buscan fragmentos similares (contexto) en Pinecone.
3. El contexto se envÃ­a al modelo de lenguaje.
4. El modelo responde con base en esa informaciÃ³n.

---

## ğŸ“· Ejemplo de EjecuciÃ³n

```
ğŸ’¬ Pregunta (o 'exit'): Â¿QuÃ© es un inteligencia aritificial?
ğŸ¤– La inteligencia artificial es una rama de la ciencia de la computaciÃ³n dedicada a crear mÃ¡quinas y sistemas que pueden realizar tareas que normalmente requieren de la inteligencia humana.
```

---

## ğŸ§° Estructura de Archivos Clave

| Archivo                | DescripciÃ³n                                           |
| ---------------------- | ----------------------------------------------------- |
| `ingest_data.py`       | Carga documentos, los divide y los indexa en Pinecone |
| `query_rag.py`         | Crea el pipeline RAG (Retriever + Generator)          |
| `verificar_indices.py` | Lista Ã­ndices existentes y sus estadÃ­sticas           |
| `.env_example`         | Ejemplo de configuraciÃ³n para API Keys                |
| `requirements.txt`     | Lista de dependencias del proyecto                    |

---

## ğŸ§‘â€ğŸ’» Autor

**Geronimo**
ğŸ‘¤ GitHub: [@MimiRandomS](https://github.com/MimiRandomS)

---

## â­ Agradecimientos

* [LangChain Documentation](https://python.langchain.com/docs)
* [OpenAI API Docs](https://platform.openai.com/docs)
* [Pinecone Python SDK](https://github.com/pinecone-io/pinecone-python-client)
* Inspirado en el laboratorio:
  **"Introduction to Creating RAGs with OpenAI"**
